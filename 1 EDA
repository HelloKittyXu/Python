EDA
1.What is EDA(Exploratory Data Analysis)？
EDA是探索数据的过程，通常包括数据结构、组成成分、数据分布、变量间关系。在EDA过程中，最重要的工具是可视化图表。

2.Goals？
1 验证数据是否正常合理
2 判断这些数据能否回答研究的问题
3 对研究的问题给出初步答案

一、探查数据质量和数据类型
1.查看数据类型
1.1基础数据结构——数据框（DataFrame）
#导入pandas
import pandas as pd
#读取数据
df = pd.read_table(' .csv' 文件名, seq=',')
#取出列数据
df[['', '', '']]
#条件索引
df.loc[df.sex == '']
( df.loc[df['sex'] == ''] )
1.2基础数据情况
#查看整体数据情况
df.head()
df.info() --展示整体状况，多少列、列属性、是否有空值等
#数据类型转换
df.astype()
df['Pclass2'] = df['Pclass'].astype('category')
2.查看缺失值及处理
#判断缺失值
df.info()
df.isnull.sum()
#缺失值处理
df.fillna(method = '') --填充
  绝对值填充（0，mean()，中位数），可通过字典对不同列填充不同值
  method填充（'ffill'，'bfill'），前向填充：空值前面的非空值，后向填充：空值后面的非空值
  pad/ffill：向前填充，可以简写为df.ffill()
  bfill/backfill：向后填充，可以简写为df.bfill()
df.dropna() --删除，可按指定行/列删除为空的数据

二、探查数据基础分布情况
1.分类变量
1.1频数——柱状/条形图（barplot）
seaborn.countplot(data = df #数据集, x = 'sex' #分类变量)
1.2占比——扇形图（pieplot）
sex_freq = df['sex'].value_counts()
plt.pie(x = sex_freq #数据集, labels = sex_freq.index #分类标签名称, startangle = 90 #起始角度 90°, autopct = '%l.f%%' #添加占比，设置文本格式)
2.连续变量
2.1统计量
pd.describe() #返回count mean std min max等统计量
pd.Series.mean()
pd.Series.std()
2.2分布——直方图（histogram）
df.Series.hist(bins = 10 #分为等距的10桶)
#条形图 连续变量离散化
df['Age2'] = pd.cut(x = df.Age #数据源, bins = [0,10,20,40,50,80] #分组区间, labels = ['0~10','10~20','20~40','40~50','50~80'] #分组名称) #根据max min决定分区
#箱线图（boxplot）
sns.boxplot(data = df, y = 'Age')
箱线图识别异常点的原理：
Q1:下四分位数（25%）
Q3:上四分位数（75%）
IQR：四分位距，IQR = Q3 - Q1
上限 = Q3 + 1.5*IQR
下限 = Q1 - 1.5*IQR
如果max <= 上限，则延长上限为最大值，延长下限同理
#核密度估计图（kdeplot）
非参数检验方法，用来估计未知的密度函数，可以直观看出数据样本本身分布特征
sns.kdeplot(df['Age'])
#distplot
在直方图的基础上，增加核密度曲线
sns.distplot(df['Age'], bins = 10)
3.时间序列
需要规范时间轴格式
3.1将时间变量转化为datetime.date格式
3.2作图
3.3配置横坐标格式

from datetime import datetime
import matplotlib.dates as mdates #引用日期格式组件
#生成横纵坐标信息，调整时间格式
x = uv_date.date
y = uv_date.uv

#配置横坐标
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))
plt.gca().xaxis.set_major_locator(mdates.DayLocator())

#正常作图
plt.plot(x, y, #label = '',# linestyle = '-', color = 'orange')
plt.xticks(rotation = 90) #x轴标签旋转90°

#设置横坐标格式
plt.xticks(pd.date_range('', '', freq = '5D'))

4.异常值检测
4.1 3倍标准差：单列检验，数据需服从正态分布
mean = df[''].mean()
std = df[''].std()
upper = mean + 3*std #上限
lower = mean - 3*std #下限

4.2.1 Kmeans聚类
Kmeans核心：组内距离小，组间距离大，适用于凸样本
优点：容易实现，计算高效

#导入kmeans包
from sklearn.cluster import KMeans

#kmeans聚类
kmeans = KMeans(n_clusters =  #分组个数, random_state = 0).fit(beijing[['call', 'finish']] #数据源)
#print(kmeans.labels_)

#分组标签
beijing['type'] = kmeans.labels_

#绘图观察
plt.scatter(x = beijing.loc[beijing['type'] == 0].call, y = beijing.loc[beijing['finish'] == 0].finish, c = 'red', marker = 's', label = 'type 0')
plt.scatter(x = beijing.loc[beijing['type'] == 1].call, y = beijing.loc[beijing['finish'] == 1].finish, c = 'blue', marker = '.', label = 'type 1')
plt.scatter(x = beijing.loc[beijing['type'] == 2].call, y = beijing.loc[beijing['finish'] == 2].finish, c = 'orange', marker = '.', label = 'type 2')
plt.scatter(x = beijing.loc[beijing['type'] == 3].call, y = beijing.loc[beijing['finish'] == 3].finish, c = 'green', marker = '.', label = 'type 3')
plt.legend() #图例

4.2.2 Dbscan聚类
Dbscan是一种基于密度空间的聚类算法，适用于非凸样本
优点：识别复杂形状
dbscan = cluster.DBSCAN(eps = 0.2, min_samples = 5, metric = 'euclidean')
y_db = dbscan.fit_predict(x)

三、探索变量之间的关系
1.分类 x 分类
1.1 列联表
#按列分组
group1 = df.groupby('key1')
group2 = df.groupby(['key2', 'key2'])
#聚合函数
g1.count()
#基于pivot_table（类似数据透视表）列联表
pd.pivot_table(df, index = 'key1', columns = 'key2', aggfunc = )
#基于crosstab
pd.crosstab(df.sex, df.survived, margins = True)

1.2 热力图 #多x多
x = pd.crosstab(df.Type, df.Size)
sns.heatmap(x, annot = True #显示数据标签, fmt = '.0f' #数据格式, #mask = x.values < 200 覆盖小于200的区域, cmap = 'Blues' #设定颜色)

1.3 关联性分析
卡方检验：两个分类变量的关联分析，要求样本量足够大，样本过小可能出现错误
判断核心：看频数和期望是否一致
#性别与存活率列联表
d = df[['PassengerId', 'Sex', 'Survived']].groupby['Sex', 'Survived'].count()
print(d)
from scipy import stats
#卡方检验
stats.chisquare(d)
#p值显著性水平小于0.05

2.分类 x 连续
2.1 分布情况
2.1.1 基于barplot观察不同分类类别下变量的分布差异
sns.barplot(data = df , x = 'Sex' #按x分组, hue = '' #次级分类变量 , y = 'Fare' #对y做统计, estimator = np.mean #支持多种统计量，默认为均值)
2.1.2 基于堆叠kdeplot、distplot不同分类类别下变量的分布差异
#kdeplot
df2 = df.loc[df['Fare'] <= 100]
male = sns.kdeplot(df2.loc[df2['Sex'] == 'male'].Fare, color = 'b', label = '男性')
female = sns.kdeplot(df2.loc[df2['Sex'] == 'female'].Fare, color = 'r', label = '女性')
#distplot
male = sns.distplot(df2.loc[df2['Sex'] == 'male'].Fare, his_kws = { 'linewidth' : 2, 'alpha' : 0.7, 'color' : 'b'} #设置格式 , kde_kws = {'label' : '男性'} #设置图例)
female = sns.distplot(df2.loc[df2['Sex'] == 'female'].Fare, his_kws = { 'linewidth' : 2, 'alpha' : 0.7, 'color' : 'r'} #设置格式 , kde_kws = {'label' : '女性'} #设置图例)
2.1.3 基于violinplot不同分类类别下变量的分布差异
箱线图中所有绘图组件都对应于实际数据点，小提琴绘图以基础分布的核密度估计为特征
#与boxplot类似
sns.violinplot(data = df2, x = 'Sex', y = 'Fare', hue = 'Pclass' #次级分类变量)

2.2 均值检验
对两个类别分类变量进行Z检验、T检验（均值）
如何选择T检验、Z检验：
(1) 样本量大：T检验 or Z检验 都可，大样本情况下，两者结果近似
(2) 样本量小：
总体已知方差 Z检验
总体未知方差 T检验
#假设男性、女性花费相同
male_fare = df2.loc[df2['Sex'] == 'male'].Fare
female_fare = df2.loc[df2['Sex'] == 'female'].Fare
#用ttest_ind做T检验，要求输入原始样本数据
t_stats, p_value = stats.ttest_ind(male_fare, female_fare)
print('P value is %.10f%' %(p_value)) #双边检验

2.3 方差分析
多个类别分类变量——方差分析（ANOVA）
核心思想：总误差 = 组内误差 + 组间误差
前提条件：（1）每个总体都服从正态分布（2）总体方差相同（3）观测值独立
需要做：（1）正态性检验（2）方差齐性检验
2.3.1 正态性检验
#绘制直方图
plt.figure(figsize = (12,8))
plt.subplot(221)
df2.loc[df2[' '] == ''].Avg_price.hist()
#kstest 是一个很强大的检验模块，除了正态性检验
#还能检验 scipy.stats 中的其他数据类型分布
from scipy import stats
c1 = df2.loc[df2[' '] == ''].SalePrice
c2 = df2.loc[df2[' '] == ''].SalePrice
c3 = df2.loc[df2[' '] == ''].SalePrice
#标准化
normed_c1 = (c1 - c1.mean())/c1.std()
normed_c2 = (c2 - c2.mean())/c2.std()
normed_c3 = (c3 - c3.mean())/c3.std()
print(stats.kstest(normed_c1, 'norm'))
print(stats.kstest(normed_c2, 'norm'))
print(stats.kstest(normed_c3, 'norm'))
#结果返回两个值：statistic —> D值，pvalue —> P值
#p值>0.05，可以认为服从正态分布

2.3.2 方差齐性检验
#方差齐性检验（莱文检验，levene）
import scipy
scipy.stats.levene(c1, c2, c3)
#检验结果p>0.05，所以可以认为方差是相等的

#单因素方差分析
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
#不同社区（Neighborhood）
formula = 'Avg_price-Neighborhood'
anova_results = anova_lm(ols(formula, df2).fit())
print(anova_results)
#p值<0.05，可以拒绝原假设（不同社区对房价没有影响），可以认为社区对售价有显著影响

3.连续 x 连续
3.1 图
3.1.1 散点图：看2个连续变量的趋势，发现潜在规律
sns.scatterplot(date = df3, x = '', y = '', hue = '' #分组)
3.1.2 jointplot
sns.jointplot(date = df3, x = '', y = '', hue = '' #分组)
3.1.3 pairplot
一键生成，快速画出各个特征的分布
iris = sns.load_dataset('iris')
g = sns.pairplot(iris)

3.2 相关系数
3.2.1 线性相关
Pearson相关系数：两个变量x、y之间协方差和标准差的比值
from scipy.stats import pearsonr
x = df3['SalePrice'] #房价
y = df3['GrLivArea'] #居住面积
#计算pearson相关系数
r_row, p_value = pearsonr(x, y)
print(r_row.round(3)) #pearson相关系数
print(p_value.round(3)) #p值
3.2.1 非线性相关
Spearman（等级）相关系数：两个变量x、y之间的单调函数；使用广泛，只要成对出现、可排序就行
p = 1 - (6 Sigma d^2)/(n * (n^2 - 1))
from scipy.stats import spearmanr
r_row, p_value = spearmanr(x, y)
print(r_row.round(3)) #spearman相关系数
print(p_value.round(3)) #p值

3.3 热力图
对相关系数矩阵绘制热力图，看变量间相关性强弱关系
sns.heatmap(df.corr(), annot = True #显示数据标签, fmt = '.2f' #数据格式, #mask = x.values < 200 覆盖小于200的区域, cmap = 'Blues' #设定颜色)

Link：
https://github.com/ResidentMario/missingno#quickstart
